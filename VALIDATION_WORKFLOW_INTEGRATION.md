# Website Validation Workflow Integration

## ğŸ¯ Architecture Overview

We now have a **two-tier validation system** that balances speed and accuracy:

### Tier 1: Simple HTTP Validation (During Scraping)
- **When**: During Outscraper business scraping
- **Speed**: ~100ms per business
- **Purpose**: Filter out obviously bad URLs
- **Technology**: Simple HTTP HEAD/GET requests
- **Rejects**:
  - Social media profiles (Facebook, Instagram, LinkedIn, etc.)
  - Google Maps redirects
  - Directory listings (Yelp, YellowPages, etc.)
  - Invalid URL formats

### Tier 2: Deep Playwright Validation (After Scraping)
- **When**: Asynchronously after businesses are saved
- **Speed**: ~4-5 seconds per business
- **Purpose**: Deep content analysis and quality scoring
- **Technology**: Playwright headless browser with stealth
- **Extracts**:
  - Contact information (phone, email, address)
  - Business hours
  - Content quality metrics
  - Quality score (0-100)
  - Placeholder detection

## ğŸ”„ Complete Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. SCRAPING (Outscraper)                               â”‚
â”‚     Get businesses from Google Maps                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. SIMPLE VALIDATION (Fast - 100ms)                    â”‚
â”‚     âœ… Valid HTML website â†’ PASS (status=pending)       â”‚
â”‚     âŒ Social media â†’ REJECT (status=invalid)           â”‚
â”‚     âŒ Google redirect â†’ REJECT (status=invalid)        â”‚
â”‚     âŒ No URL â†’ SKIP (status=no_website)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. QUALIFICATION & SAVE                                â”‚
â”‚     Calculate lead score, save to database              â”‚
â”‚     Collect business IDs that passed simple validation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. QUEUE DEEP VALIDATION (Async)                       â”‚
â”‚     Batch businesses (10 per task)                      â”‚
â”‚     Queue Celery tasks for Playwright validation        â”‚
â”‚     â†’ Scraping completes here (FAST!)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼ (Asynchronous in background)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. PLAYWRIGHT VALIDATION (Slow - 4-5s per business)    â”‚
â”‚     Launch headless browser with stealth                â”‚
â”‚     Extract contact info, analyze content               â”‚
â”‚     Calculate quality score                             â”‚
â”‚     Update business.website_validation_result           â”‚
â”‚     Update business.website_validation_status           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš™ï¸ Configuration

All validation settings are in `backend/core/config.py`:

```python
# Enable/disable auto-validation after scraping
ENABLE_AUTO_VALIDATION: bool = True

# Max businesses per validation batch (controls queue size)
VALIDATION_BATCH_SIZE: int = 10

# Disable screenshots for performance
VALIDATION_CAPTURE_SCREENSHOTS: bool = False

# Timeout per website (milliseconds)
VALIDATION_TIMEOUT_MS: int = 30000  # 30 seconds
```

### Environment Variables

Add to `.env` file (optional - defaults shown above):

```bash
# Validation Configuration
ENABLE_AUTO_VALIDATION=true
VALIDATION_BATCH_SIZE=10
VALIDATION_CAPTURE_SCREENSHOTS=false
VALIDATION_TIMEOUT_MS=30000
```

## ğŸ“Š Database Schema

### Business Fields

```sql
-- Simple validation status (set during scraping)
website_validation_status VARCHAR(30)
  -- Values: pending, valid, invalid, no_website, error

-- Deep validation result (JSONB, set by Playwright)
website_validation_result JSONB
  -- Contains: quality_score, phones, emails, has_contact_info, etc.

-- Validation timestamp
website_validated_at TIMESTAMP

-- Screenshot URL (optional - currently disabled)
website_screenshot_url TEXT
```

## ğŸ” Validation Status Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scraping   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
  Has Website?
       â”‚
    â”Œâ”€â”€â”´â”€â”€â”
    NO    YES
    â”‚     â”‚
    â–¼     â–¼
no_website  Simple Check
            â”‚
         â”Œâ”€â”€â”´â”€â”€â”
      PASS   FAIL
       â”‚      â”‚
       â–¼      â–¼
   pending  invalid
       â”‚
       â–¼
  Queue Deep
  Validation
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Playwright  â”‚
â”‚  Validation  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
    â”Œâ”€â”€â”´â”€â”€â”
   PASS  FAIL
    â”‚     â”‚
    â–¼     â–¼
  valid  invalid
```

## ğŸš€ Performance Impact

### Before (Blocking Validation)
```
Scrape 100 businesses
â”œâ”€ Outscraper API: ~5s
â”œâ”€ Simple validation: 100 * 0.1s = 10s
â””â”€ Deep validation: 100 * 4s = 400s  âŒ BLOCKS SCRAPING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 415 seconds (7 minutes)
```

### After (Async Validation)
```
Scrape 100 businesses
â”œâ”€ Outscraper API: ~5s
â”œâ”€ Simple validation: 100 * 0.1s = 10s
â”œâ”€ Save & queue: ~1s
â””â”€ Deep validation: ASYNC (doesn't block) âœ…
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total scraping: 16 seconds
Deep validation: Happens in background via Celery
```

**Result: ~25x faster scraping!** ğŸ‰

## ğŸ“ Code Examples

### Triggering Validation Manually

```python
from tasks.validation_tasks import validate_business_website

# Validate a single business
task = validate_business_website.delay("business-uuid-here")
print(f"Queued validation: {task.id}")
```

### Batch Validation

```python
from tasks.validation_tasks import batch_validate_websites

# Validate multiple businesses
business_ids = ["uuid-1", "uuid-2", "uuid-3"]
task = batch_validate_websites.delay(business_ids)
```

### Checking Validation Results

```python
from models.business import Business
from core.database import get_sync_db

db = next(get_sync_db())
business = db.query(Business).filter(Business.id == "uuid").first()

print(f"Status: {business.website_validation_status}")
print(f"Quality Score: {business.website_validation_result.get('quality_score')}")
print(f"Has Phone: {business.website_validation_result.get('has_phone')}")
print(f"Has Email: {business.website_validation_result.get('has_email')}")
```

## ğŸ§ª Testing

### Test Simple Validation

```bash
cd /var/www/webmagic/backend
source .venv/bin/activate
python scripts/test_validation_workflow.py
```

Expected output:
```
ğŸ” Testing Simple Validation (Used During Scraping)
============================================================

âœ… PASS - Valid site
  URL: https://example.com
  Valid: True
  Real Website: True

âŒ REJECT - Social media (should reject)
  URL: https://facebook.com/somebusiness
  Valid: False
  Real Website: False
  Reason: Social media or directory listing, not a real website
```

### Test Playwright Validation

```bash
python scripts/test_playwright_validation.py
```

## ğŸ”§ Celery Worker Configuration

Make sure the validation queue is enabled:

```bash
# Check current workers
supervisorctl status

# Update celery worker config
nano /etc/supervisor/conf.d/webmagic.conf

# Add validation to queue list:
command=/var/www/webmagic/backend/.venv/bin/celery -A celery_app worker \
  -Q celery,generation,scraping,campaigns,monitoring,validation \
  --loglevel=info

# Reload supervisor
supervisorctl reread
supervisorctl update
supervisorctl restart webmagic-celery
```

## ğŸ“ˆ Monitoring

### Check Validation Queue

```bash
# In Python/iPython
from celery_app import celery_app
inspect = celery_app.control.inspect()

# See queued validation tasks
inspect.active_queues()

# See running validation tasks
inspect.active()
```

### Check Validation Stats

```bash
curl "https://web.lavish.solutions/api/v1/validation/stats" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

Response:
```json
{
  "total_businesses": 500,
  "total_with_websites": 350,
  "pending": 50,
  "valid": 200,
  "invalid": 100,
  "no_website": 150,
  "error": 0
}
```

## ğŸ›ï¸ Disabling Auto-Validation

If you want to disable automatic validation after scraping:

```bash
# In .env file
ENABLE_AUTO_VALIDATION=false
```

Then trigger validation manually:

```bash
curl -X POST "https://web.lavish.solutions/api/v1/validation/validate-all-pending" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

## ğŸ”’ Security & Best Practices

1. **Rate Limiting**: Validation is batched (10 per task) to avoid overwhelming target websites
2. **Timeouts**: Each validation has a 30-second timeout to prevent hanging
3. **Error Handling**: Failures don't crash scraping - they're logged and retried
4. **Resource Management**: Playwright processes are properly cleaned up
5. **Bot Detection**: Stealth measures in place to avoid being blocked
6. **No Screenshots**: Disabled by default to save resources and speed up validation

## ğŸ› Troubleshooting

### Validation Tasks Not Running

```bash
# Check if validation queue is active
supervisorctl status webmagic-celery

# Check celery logs
tail -f /var/log/webmagic/celery.log | grep validation
```

### High Validation Queue

```bash
# Check queue size
celery -A celery_app inspect active_queues

# Temporarily increase batch size in .env
VALIDATION_BATCH_SIZE=20

# Or disable auto-validation
ENABLE_AUTO_VALIDATION=false
```

### Validation Timing Out

```bash
# Increase timeout in .env (milliseconds)
VALIDATION_TIMEOUT_MS=60000  # 60 seconds
```

## ğŸ“š Related Documentation

- [PLAYWRIGHT_VALIDATION_DESIGN.md](./PLAYWRIGHT_VALIDATION_DESIGN.md) - Complete system architecture
- [PLAYWRIGHT_SETUP_INSTRUCTIONS.md](./PLAYWRIGHT_SETUP_INSTRUCTIONS.md) - Installation guide
- [PLAYWRIGHT_IMPLEMENTATION_SUMMARY.md](./PLAYWRIGHT_IMPLEMENTATION_SUMMARY.md) - Implementation details

## âœ… Summary

**The validation workflow is now optimized for performance:**

âœ… **Fast scraping** - Simple validation doesn't block (100ms per business)  
âœ… **Deep analysis** - Playwright validation runs asynchronously in background  
âœ… **No screenshots** - Disabled for performance (user requested)  
âœ… **Configurable** - Enable/disable via environment variables  
âœ… **Scalable** - Batched processing prevents queue overwhelm  
âœ… **Reliable** - Comprehensive error handling and retries  

**This architecture ensures scraping stays fast while still providing comprehensive website validation!** ğŸš€

