# üåê Geo-Grid Enhanced Business Discovery System

## Overview

We've dramatically improved the business discovery system with **geographic grid subdivision** and **website validation**. This ensures maximum coverage of businesses in each city and accurately identifies which businesses need websites.

---

## üÜï What's New

### 1. **Geo-Grid Subdivision System**

**Problem:** Google Maps searches are location-biased. Searching "plumbers in Los Angeles" only returns results near downtown, missing businesses in Hollywood, Venice Beach, Santa Monica, etc.

**Solution:** Automatically subdivide cities into geographic zones based on population:

| City Size | Grid Size | Zones | Example |
|-----------|-----------|-------|---------|
| 1M+ people | 5√ó5 | 25 zones | Los Angeles, NYC |
| 500K-1M | 4√ó4 | 16 zones | Austin, Seattle |
| 250K-500K | 3√ó3 | 9 zones | Tampa, Raleigh |
| 100K-250K | 2√ó2 | 4 zones | Burbank, Denton |

Each zone is searched independently using GPS coordinates, ensuring complete metropolitan area coverage.

### 2. **Website Validation**

**Problem:** Many Google Maps listings have invalid website URLs:
- Dead links (404 errors)
- Social media profiles (not real websites)
- Google Maps redirects
- Parked domains

**Solution:** Automatic website validation that:
- ‚úÖ Checks if URL is accessible (HTTP 200)
- ‚úÖ Validates it's not just a social media profile
- ‚úÖ Detects Google Maps redirects
- ‚úÖ Verifies actual content exists
- ‚úÖ Identifies businesses that truly need websites

### 3. **Expanded Business Categories**

Added **200+ niche categories** including:
- Emergency services (24-hour plumbers, emergency electricians)
- Specialized medical (plastic surgeons, fertility clinics, pain management)
- Specialized legal (immigration lawyers, DUI attorneys, medical malpractice)
- Specialized home services (mold remediation, foundation repair, water damage restoration)
- Technology services (IT support, managed services, security cameras)
- And many more!

See `backend/scripts/business_categories.py` for the complete list.

---

## üìä Coverage Comparison

### Traditional Approach (OLD)
```
Search: "plumbers in Los Angeles, CA"
Results: ~50 businesses near downtown LA
Coverage: ~10 km¬≤ (city center only)
Cost: $0.50
Problem: Misses 80%+ of metropolitan area
```

### Geo-Grid Approach (NEW)
```
Search: 25 zones covering entire LA metro area
Results: ~1,250 businesses across all neighborhoods
Coverage: ~400 km¬≤ (entire metropolitan area)
Cost: $12.50
Benefit: Complete systematic coverage, 25x more businesses
```

**Cost per business:** Same ($0.01), but with **25x more coverage**

---

## üöÄ How It Works

### Step 1: City Analysis
```python
population = 3_900_000  # Los Angeles
should_subdivide = population >= 100_000  # True!
```

### Step 2: Grid Creation
```python
zones = create_city_grid(
    city="Los Angeles",
    state="CA",
    center_lat=34.0522,
    center_lon=-118.2437,
    population=3_900_000
)
# Creates 5x5 grid = 25 zones
```

### Step 3: Zone-Based Searching
```python
for zone in zones:
    search_query = f"plumbers near {zone.center_lat},{zone.center_lon}"
    # Searches specific geographic area
    # Google Maps returns businesses near these coordinates
```

### Step 4: Website Validation
```python
async with WebsiteValidator() as validator:
    results = await validator.validate_batch(website_urls)
    
# Results:
# ‚úÖ Valid: Working business website
# ‚ùå Invalid: Dead link, social media, or placeholder
```

### Step 5: Duplicate Prevention
```python
# Each business has unique gmb_id (Google My Business ID)
# System automatically skips duplicates across zones
# Businesses near zone boundaries won't be counted twice
```

---

## üó∫Ô∏è Database Schema Updates

### New Coverage Grid Fields

```sql
ALTER TABLE coverage_grid ADD COLUMN zone_id VARCHAR(20);
ALTER TABLE coverage_grid ADD COLUMN zone_lat VARCHAR(20);
ALTER TABLE coverage_grid ADD COLUMN zone_lon VARCHAR(20);
ALTER TABLE coverage_grid ADD COLUMN zone_radius_km VARCHAR(10);
```

**Example Coverage Entry (Zoned):**
```json
{
  "id": "uuid-here",
  "country": "US",
  "state": "CA",
  "city": "Los Angeles",
  "industry": "plumbers",
  
  "zone_id": "3x2",  // Row 3, Column 2
  "zone_lat": "34.0652",
  "zone_lon": "-118.2895",
  "zone_radius_km": "4.0",
  
  "status": "completed",
  "lead_count": 47,
  "qualified_count": 32
}
```

### Business Schema (No Changes Needed)

The `businesses` table already supports all necessary fields. We just populate new fields:
- `has_valid_website` - Boolean (from website validation)
- `website_status` - "valid" | "invalid" | "none"
- `website_validation_error` - Error message if invalid

---

## üíª Usage Examples

### Example 1: Single City with Zones

```python
from services.hunter.hunter_service import HunterService

async with get_db_session() as db:
    hunter = HunterService(db)
    
    result = await hunter.scrape_location_with_zones(
        city="Austin",
        state="TX",
        industry="plumbers",
        population=990_000,
        city_lat=30.2672,
        city_lon=-97.7431,
        limit_per_zone=50
    )
    
    print(f"Zones scraped: {result['zones_scraped']}")
    print(f"Businesses found: {result['total_saved']}")
```

### Example 2: Check If City Should Subdivide

```python
from services.hunter.geo_grid import should_subdivide_city, create_city_grid

population = 350_000

if should_subdivide_city(population):
    zones = create_city_grid(
        city="Tampa",
        state="FL",
        center_lat=27.9506,
        center_lon=-82.4572,
        population=population
    )
    print(f"Created {len(zones)} zones")  # 9 zones (3x3 grid)
else:
    print("Single search sufficient")
```

### Example 3: Website Validation

```python
from services.hunter.website_validator import WebsiteValidator

urls = [
    "https://businesswebsite.com",
    "facebook.com/somebusiness",
    "https://parked-domain.com"
]

async with WebsiteValidator() as validator:
    results = await validator.validate_batch(urls)
    
    for result in results:
        print(f"{result.url}: {'‚úÖ Valid' if result.is_valid else '‚ùå Invalid'}")
        if not result.is_valid:
            print(f"  Reason: {result.error_message}")
```

---

## üß™ Testing the System

### Demo Script

```bash
cd backend

# Compare strategies (no actual scraping)
python scripts/demo_geo_grid_scraping.py \
    --city "Los Angeles" \
    --state "CA" \
    --industry "plumbers" \
    --compare

# Run actual scraping with zones
python scripts/demo_geo_grid_scraping.py \
    --city "Austin" \
    --state "TX" \
    --industry "dentists" \
    --limit 50
```

### Test Website Validator

```bash
cd backend
python -m services.hunter.website_validator
```

### Test Geo-Grid Generation

```bash
cd backend
python -m services.hunter.geo_grid
```

---

## üìà Expected Results

### Coverage Improvement

| Metric | Old System | New System | Improvement |
|--------|-----------|-----------|-------------|
| Businesses per city | ~50 | ~1,000+ | 20x more |
| Geographic coverage | ~10 km¬≤ | ~400 km¬≤ | 40x more |
| Duplicate rate | 5-10% | <1% | Better dedup |
| Valid websites | ~60% | ~95% | Verified |

### Cost Efficiency

- **Cost per business:** Same (~$0.01)
- **Coverage per dollar:** 20x better
- **Valid leads:** Higher quality (website validation)

---

## üîß Configuration

### Adjust Grid Sizes

Edit `backend/services/hunter/geo_grid.py`:

```python
def calculate_grid_size(population: int) -> Tuple[int, int]:
    if population >= 1_000_000:
        return (6, 6)  # 36 zones for mega-cities (increased from 5x5)
    # ... etc
```

### Adjust Search Radius

```python
def calculate_search_radius(population: int) -> float:
    if population >= 1_000_000:
        return 3.0  # Smaller radius = more precision (decreased from 4.0)
    # ... etc
```

### Website Validation Timeout

```python
validator = WebsiteValidator(timeout=10)  # 10 seconds (default: 8)
```

---

## üö® Important Notes

### 1. **API Costs Scale with Zones**

- 1 city with 25 zones = 25 API calls = $12.50
- Plan accordingly for large-scale campaigns
- But: You get 25x more businesses, so cost per business is the same

### 2. **Duplicate Prevention Across Zones**

- Businesses near zone boundaries may appear in multiple zone searches
- System automatically detects and skips duplicates using `gmb_id`
- Database logs show: "Skipped X duplicates"

### 3. **Website Validation Takes Time**

- Validating 1,000 websites takes ~2-3 minutes
- Run in batches with max_concurrent=10 (default)
- Increase for faster validation (but watch rate limits)

### 4. **City Coordinates Required**

- For geo-grid scraping, you need city center lat/lon
- Populate from `backend/scripts/seed_us_cities.py`
- Or use a geocoding service

---

## üéØ Recommended Workflow

### Phase 1: Seed Cities with Coordinates

```bash
cd backend
python scripts/seed_us_cities.py
# Populates 346 major US cities with lat/lon/population
```

### Phase 2: Test with One City

```bash
python scripts/demo_geo_grid_scraping.py \
    --city "Denver" \
    --state "CO" \
    --industry "plumbers" \
    --limit 50
```

### Phase 3: Review Results

```sql
-- Check coverage grids created
SELECT city, zone_id, lead_count, qualified_count 
FROM coverage_grid 
WHERE city = 'Denver' 
ORDER BY zone_id;

-- Check businesses found
SELECT name, city, website_url, has_valid_website
FROM businesses
WHERE city = 'Denver'
LIMIT 20;
```

### Phase 4: Scale Up

Enable automated discovery campaigns using the Coverage Page:
1. Manual test: 5-10 searches
2. Review results
3. Enable scheduled scraping for high-priority grids

---

## üìö Related Files

| File | Purpose |
|------|---------|
| `backend/services/hunter/geo_grid.py` | Geo-grid subdivision logic |
| `backend/services/hunter/website_validator.py` | Website validation service |
| `backend/services/hunter/hunter_service.py` | Updated scraping orchestration |
| `backend/models/coverage.py` | Coverage model with zone fields |
| `backend/migrations/003_add_geo_grid_zones.sql` | Database migration |
| `backend/scripts/business_categories.py` | 200+ business categories |
| `backend/scripts/demo_geo_grid_scraping.py` | Demo script |

---

## üéâ Summary

### What You Get

‚úÖ **25x more businesses** per city through zone-based searching  
‚úÖ **Complete geographic coverage** of entire metropolitan areas  
‚úÖ **Verified website status** - know who truly needs a website  
‚úÖ **200+ niche categories** for targeted discovery  
‚úÖ **Automatic duplicate prevention** across zones  
‚úÖ **Same cost per business** ($0.01) with 25x more coverage  

### Next Steps

1. ‚úÖ Run the demo script to see it in action
2. ‚úÖ Review the results in your database
3. ‚úÖ Adjust grid sizes/radii if needed
4. ‚úÖ Enable automated campaigns
5. ‚úÖ Start generating websites for qualified leads!

---

**Questions? Issues?**

Check the logs in `conductor.log` or enable debug logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

Happy discovering! üöÄ

